# configs/tools.yaml
toolbank:
  freeze_backbone: true

  # action별 LoRA 설정 (3090 기준 추천)
  adapters:
    A_DEDROP:
      rank: 2
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 1.0

    A_DEBLUR:
      rank: 2
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 1.0

    A_DERAIN:
      rank: 2
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 1.0

    A_DENOISE:
      rank: 2
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 1.0

    A_DEHAZE:
      rank: 2
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 1.0

    A_HYBRID:
      rank: 1
      alpha: 1.0
      dropout: 0.0
      runtime_scale: 0.8

train:
  lr: 0.0002
  weight_decay: 0.0
  betas: [0.9, 0.999]

  epochs: 20
  grad_clip: 1.0

  amp: true
  log_every: 50
  save_every: 250
  resume_path: E:/ReAct-IR/checkpoints/toolbank/epoch_001_loss0.1042.pth
  save_best: true

paths:
  ckpt_dir: "E:/ReAct-IR/checkpoints/toolbank"
  log_dir:  "E:/ReAct-IR/results/quantitative"
  vis_dir:  "E:/ReAct-IR/results/qualitative"
